# ëœë¤(ë‚œìˆ˜) ê°’ ë¬¸ì œ ë° í•´ê²° ë°©ë²•
ë¬¸ì œ 1: S3 íŒŒì¼ ì—…ë¡œë“œ ë° DynamoDB ì—°ë™ (ë™ì  ì ìˆ˜ ë¶€ì—¬)
ì‹œë‚˜ë¦¬ì˜¤:
ë‹¹ì‹ ì€ ìƒˆë¡œìš´ í•™ìƒ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§¤ì¼ S3 ë²„í‚·ì— ìƒˆë¡œìš´ í•™ìƒ ì •ë³´ê°€ ë‹´ê¸´ CSV íŒŒì¼ì´ ì—…ë¡œë“œë©ë‹ˆë‹¤. 
ì´ íŒŒì¼ì—ëŠ” í•™ìƒ ì´ë¦„, í•™ë²ˆ, ì „ê³µì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ CSV íŒŒì¼ì„ ì½ì–´ DynamoDB í…Œì´ë¸”ì— 
í•™ìƒ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” AWS Lambda í•¨ìˆ˜ë¥¼ ê°œë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

S3 ë²„í‚· ì´ë¦„ì€ sgu-<awsê³„ì •>-s3ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.
CSV íŒŒì¼ëª…ì€ student_scores_<í˜„ì¬ ë‚ ì§œ>.csv (ì˜ˆ: student_scores_20250613.csv) í˜•ì‹ìœ¼ë¡œ ì—…ë¡œë“œë©ë‹ˆë‹¤.
CSV íŒŒì¼ì˜ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì„ ê°€ì§‘ë‹ˆë‹¤ (íŒŒì¼ í•˜ë‚˜ì— ì—¬ëŸ¬ ì¤„ì˜ ë°ì´í„°):
'''
ì´ë¦„,í•™ë²ˆ,ì „ê³µ
ê¹€ì² ìˆ˜,20230001,ì»´í“¨í„°ê³µí•™
ì´ì˜í¬,20230002,ì „ìê³µí•™
ë°•ì§€ì„±,20230003,ìŠ¤í¬ì¸ ê³¼í•™
'''
íŠ¹ì • ì¡°ê±´ (ëœë¤ ê°’ ì ìš©): ê° í•™ìƒ ë°ì´í„°ì— Score ì†ì„±ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤. ì´ Score ê°’ì€ 0ë¶€í„° 100 ì‚¬ì´ì˜ ìˆ«ìë¡œ ë¶€ì—¬í•˜ë˜,
í˜„ì¬ Lambda í•¨ìˆ˜ê°€ ì‹¤í–‰ëœ ì‹œê°„ì˜ 'ì´ˆ(second)' ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ê²°ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ë§Œì•½ í˜„ì¬ ì‹œê°„ì˜ ì´ˆê°€ 0~19ì´ˆì´ë©´ ScoreëŠ” 60ì .
ë§Œì•½ í˜„ì¬ ì‹œê°„ì˜ ì´ˆê°€ 20~39ì´ˆì´ë©´ ScoreëŠ” 80ì .
ë§Œì•½ í˜„ì¬ ì‹œê°„ì˜ ì´ˆê°€ 40~59ì´ˆì´ë©´ ScoreëŠ” 95ì .

### í˜„ì¬ Lambda í•¨ìˆ˜ê°€ ì‹¤í–‰ëœ ì‹œê°„ì˜ 'ì´ˆ(second)' ê°’ì„ í™œìš©í•˜ì—¬ Scoreë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •í•˜ê³  DynamoDBì— ì¶”ê°€í•˜ëŠ” ë¡œì§ì„ êµ¬í˜„í•˜ì„¸ìš”.
import json
import boto3
import csv
from datetime import datetime

def lambda_handler(event, context):
    s3 = boto3.client('s3')
    dynamodb = boto3.resource('dynamodb')
    
    # ì‹œí—˜ ê³µì§€ì— ë”°ë¼ í…Œì´ë¸” ì´ë¦„ ì§€ì • (ì˜ˆì‹œ: sgu-202500-3a)
    # ì‹¤ì œ ì‹œí—˜ì—ì„œëŠ” ë³¸ì¸ì˜ AWS ê³„ì • IDì™€ í•™ë…„ë°˜ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    table_name = 'sgu-<awsê³„ì •>-<í•™ë…„ë°˜>' 
    table = dynamodb.Table(table_name)

    # S3 ì´ë²¤íŠ¸ì—ì„œ ë²„í‚·ê³¼ í‚¤ ì •ë³´ ì¶”ì¶œ
    # ì‹¤ì œ S3 íŠ¸ë¦¬ê±° ì‹œ event êµ¬ì¡°ì— ë§ì¶° ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ì„ì˜ì˜ ê°’ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
    # ì‹œí—˜ì—ì„œëŠ” S3 íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸(event ë³€ìˆ˜)ì—ì„œ ë²„í‚·ê³¼ í‚¤ë¥¼ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
    bucket_name = 'sgu-<awsê³„ì •>-s3' # ë³¸ì¸ ë²„í‚· ì´ë¦„ìœ¼ë¡œ ë³€ê²½
    object_key = 'student_scores_20250613.csv' # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½ (ë‚ ì§œ í¬í•¨)

    try:
        # 1. S3ì—ì„œ CSV íŒŒì¼ ì½ê¸°
        response = s3.get_object(Bucket=bucket_name, Key=object_key)
        content = response['Body'].read().decode('utf-8')

        # 2. í˜„ì¬ Lambda í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
        current_time = datetime.now()
        processed_time = current_time.isoformat()
        
        # 3. í˜„ì¬ ì‹œê°„ì˜ 'ì´ˆ' ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ Score ê²°ì •
        # 0~19ì´ˆ: 60ì , 20~39ì´ˆ: 80ì , 40~59ì´ˆ: 95ì 
        second_value = current_time.second
        if 0 <= second_value <= 19:
            assigned_score = 60
        elif 20 <= second_value <= 39:
            assigned_score = 80
        else: # 40~59ì´ˆ
            assigned_score = 95

        # CSV ë°ì´í„°ë¥¼ í•œ ì¤„ì”© ì½ê¸°
        csv_reader = csv.reader(content.splitlines())
        header = next(csv_reader) # í—¤ë” ê±´ë„ˆë›°ê¸°

        inserted_items = []
        for row in csv_reader:
            # CSV ì»¬ëŸ¼ ë§¤í•‘
            name = row[0]
            user_id = row[1] # í•™ë²ˆì„ user_idë¡œ ì‚¬ìš©
            major = row[2]

            # DynamoDBì— ì‚½ì…í•  ì•„ì´í…œ êµ¬ì„±
            item = {
                'user_id': user_id,
                'timestamp': processed_time, # ì •ë ¬ í‚¤ë¡œ ì‚¬ìš©
                'name': name,
                'major': major,
                'Score': assigned_score, # ë™ì ìœ¼ë¡œ ê²°ì •ëœ ì ìˆ˜ ì¶”ê°€
                'ProcessedTime': processed_time # ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
            }

            table.put_item(Item=item)
            inserted_items.append(item)
            print(f"Inserted item: {item}")

        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'DynamoDB insert successful!',
                'inserted_count': len(inserted_items),
                'first_item_example': inserted_items[0] if inserted_items else {}
            }, ensure_ascii=False)
        }

    except Exception as e:
        print(f"Error: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'hint': 'S3 ë²„í‚· ë° í‚¤, DynamoDB í…Œì´ë¸” ì´ë¦„ í™•ì¸ ë˜ëŠ” S3 ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° ì„¤ì • í™•ì¸'
            }, ensure_ascii=False)
        }
  ### í˜„ì¬ ì‹œê°„ì˜ 'ë¶„' ê°’ì„ í™œìš©í•˜ì—¬ 5~10ê°œì˜ ë¡œê·¸ ì´ë²¤íŠ¸ë¥¼ ê°€ì ¸ì™€ ë¶„ì„í•˜ëŠ” ë¡œì§ì„ í¬í•¨í•˜ì„¸ìš”.
import boto3
import json
import emoji
from datetime import datetime

def lambda_handler(event, context):
    logs = boto3.client('logs')
    # ë¡œê·¸ë¥¼ ì½ì–´ì˜¬ ëŒ€ìƒ Lambda í•¨ìˆ˜ì˜ ë¡œê·¸ ê·¸ë£¹ ì´ë¦„
    log_group = '/aws/lambda/sgu-<awsê³„ì •>-some-other-lambda' 
    
    try:
        # 1. í˜„ì¬ ì‹œê°„ì˜ 'ë¶„' ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì ¸ì˜¬ ë¡œê·¸ ê°œìˆ˜ ë™ì  ê²°ì •
        # (í˜„ì¬ ë¶„ % 6)ì€ 0~5 ì‚¬ì´ì˜ ê°’ì„ ë°˜í™˜í•˜ë¯€ë¡œ, +5ë¥¼ í•˜ë©´ 5~10 ì‚¬ì´ì˜ ê°’ì´ ë©ë‹ˆë‹¤.
        current_minute = datetime.now().minute
        num_logs_to_fetch = (current_minute % 6) + 5 
        print(f"Fetching {num_logs_to_fetch} log events based on current minute: {current_minute}")

        # 2. ìµœê·¼ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
        streams = logs.describe_log_streams(
            logGroupName=log_group,
            orderBy='LastEventTime',
            descending=True,
            limit=1
        )['logStreams']

        if not streams:
            return {
                'statusCode': 404,
                'body': 'No log streams found for the specified log group.'
            }

        stream_name = streams[0]['logStreamName']
        print(f"Using log stream: {stream_name}")

        # 3. ë¡œê·¸ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë™ì ìœ¼ë¡œ ê²°ì •ëœ ê°œìˆ˜ë§Œí¼)
        events_response = logs.get_log_events(
            logGroupName=log_group,
            logStreamName=stream_name,
            limit=num_logs_to_fetch, # ë™ì ìœ¼ë¡œ ê²°ì •ëœ ê°œìˆ˜ ì ìš©
            startFromHead=False # ê°€ì¥ ìµœê·¼ ë¡œê·¸ë¶€í„° ê°€ì ¸ì˜¤ê¸° ìœ„í•´ False (í˜¹ì€ íŠ¹ì • endTime ì„¤ì •)
        )
        events = events_response['events']

        processed_messages = []
        for e in events:
            message = e['message'].strip()
            
            # 4. í‚¤ì›Œë“œì— ë”°ë¼ ì´ëª¨ì§€ ì¶”ê°€
            if "ERROR" in message.upper():
                processed_message = f"{message} âŒ"
            elif "WARNING" in message.upper():
                processed_message = f"{message} âš ï¸"
            elif "INFO" in message.upper():
                processed_message = f"{message} âœ…"
            else:
                processed_message = f"{message} ğŸ’¬"
            
            processed_messages.append(processed_message)
            print(processed_message) # Lambda ë¡œê·¸ì— ì¶œë ¥

        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': f'Processed {len(processed_messages)} CloudWatch log events.',
                'processed_logs': processed_messages
            }, ensure_ascii=False)
        }

    except logs.exceptions.ResourceNotFoundException:
        return {
            'statusCode': 404,
            'body': json.dumps({
                'error': f"Log group '{log_group}' not found. Please check the log group name."
            }, ensure_ascii=False)
        }
    except Exception as e:
        print(f"Error processing logs: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)}, ensure_ascii=False)
        }
        
